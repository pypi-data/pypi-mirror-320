{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27a47a7-54ad-4866-b16c-90933a17a9f2",
   "metadata": {
    "collapsed": false,
    "name": "Title"
   },
   "source": [
    "# Multiclass Defect Detection with Distributed training using PyTorch Object Detection Models in Snowflake Notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94dc00-422d-423d-bf6c-cbfe8ef7a175",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "headers"
   },
   "outputs": [],
   "source": [
    "!pip freeze | grep snow\n",
    "!pip install opencv-python-headless\n",
    "\n",
    "session = get_active_session()\n",
    "import torch\n",
    "import torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c1be8-b51c-44b5-b769-5f7fcd16feb1",
   "metadata": {
    "collapsed": false,
    "name": "mk1"
   },
   "source": [
    "## Install necessary packages:\n",
    "\n",
    "* torch\n",
    "* torchvision\n",
    "* opencv\n",
    "* matplotlib\n",
    "* Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c23e35-93ed-4665-afb2-4614e504827c",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "installcv"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!apt update && apt install -y libsm6 libxext6\n",
    "!apt-get install -y libxrender-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33097ff5-5bfe-49dd-a147-7e3b962919e6",
   "metadata": {
    "collapsed": false,
    "name": "mk2"
   },
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Importheader"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig\n",
    "from snowflake.ml.data.sharded_data_connector import DataConnector, ShardedDataConnector\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"distributed_ml_crt_imageanomaly_detection\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0,},\n",
    "                     \"attributes\":{\"is_quickstart\":1, \"source\":\"notebook\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9a9b6a-bdd6-40d5-bcb8-d101ed04df44",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "devices"
   },
   "outputs": [],
   "source": [
    "# Get device info\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of GPU devices available:\", num_gpus)\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        print(\"Device\", i, \":\", torch.cuda.get_device_name(i))\n",
    "    \n",
    "    #Set a default device\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    print(\"CUDA is not available. Check your installation or GPU setup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76784f73",
   "metadata": {},
   "source": [
    "## Load Data into Snowflake\n",
    "The next step is to load the PCB dataset into a Snowflake stage.\n",
    "\n",
    "Be sure to review and comply with the licensing terms and usage guidelines before utilizing the PCB dataset. Load the PCB Images from the external location into the Snowflake stage data_stage for training. \n",
    "\n",
    "Load the data from this [OSS](https://github.com/Charmve/Surface-Defect-Detection/tree/master/DeepPCB/PCBData) repository into a Snowflake stage. You need to consider images under different subfolders called groupxxxx and organize them\n",
    "\n",
    "The following code in this notebook expects the data to be in the structure :\n",
    "- Snowflake stage\n",
    "  - images\n",
    "    - train\n",
    "    - val\n",
    "  - labels\n",
    "    - train\n",
    "    - val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96e840",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The data_stage contains the PCB images loaded in the /images subfolder and the labels loaded in the /labels subfolder\n",
    "session.sql(\"ls @data_stage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccdcd7a",
   "metadata": {},
   "source": [
    "### Download Labels \n",
    "Download label files from the Snowflake stage, parse each label text file to extract label data, and then save this data into a DataFrame which is written to a Snowflake table called LABELS_TRAIN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2840e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import pandas as pd\n",
    "stage_train_path = \"@DATA_STAGE/labels\"\n",
    "local_train_dir = \"/tmp/labels/\"\n",
    "files = session.file.get(\"@DATA_STAGE/labels\", \"/tmp/labels/\")\n",
    "\n",
    "\n",
    "# Ensure local directories exist\n",
    "os.makedirs(local_train_dir, exist_ok=True)\n",
    "\n",
    "train_files = session.file.get(\"@DATA_STAGE/labels\", \"/tmp/labels/\")\n",
    "# Download .txt files from the train stage\n",
    "train_files = session.file.get(stage_train_path, local_train_dir, pattern=\".*\\\\.txt\")\n",
    "\n",
    "def download_files_from_stage(stage_path, local_dir):\n",
    "    \n",
    "    files = session.file.get(stage_path, local_dir)\n",
    "    \n",
    "    # Check if files were downloaded successfully\n",
    "    if files:\n",
    "        for file in files:\n",
    "            \n",
    "            local_file_path = os.path.join(local_dir, os.path.basename(file.file))\n",
    "            \n",
    "    else:\n",
    "        print(f\"No .txt files were downloaded from {stage_path}.\")\n",
    "\n",
    "# Download .txt files from the train stage\n",
    "download_files_from_stage(stage_train_path, local_train_dir)\n",
    "path_annot=\"/tmp/labels/\"\n",
    "\n",
    "# Initialize a list to hold all the data  \n",
    "data = []  \n",
    "  \n",
    "# Walking through the directory to get all label files  \n",
    "for path, subdirs, files in os.walk(path_annot):  \n",
    "    for name in files:  \n",
    "        if name.endswith('.txt'):  # Filter to include only .txt files  \n",
    "            full_path = os.path.join(path, name)  \n",
    "            with open(full_path, 'r') as file:  \n",
    "                for line in file:  \n",
    "                    parts = line.strip().split()  \n",
    "                    if len(parts) == 5:\n",
    "                        class_id, xmin, ymin, xmax, ymax = parts  \n",
    "                        data.append({  \n",
    "                            \"filename\": name.replace('.txt', ''),  \n",
    "                            \"class\": int(class_id),  \n",
    "                            \"xmin\": float(xmin),  \n",
    "                            \"ymin\": float(ymin),  \n",
    "                            \"xmax\": float(xmax),  \n",
    "                            \"ymax\": float(ymax)  \n",
    "                        })  \n",
    "  \n",
    "# Create a DataFrame  \n",
    "trainlabels_df = pd.DataFrame(data)\n",
    "train_labels = session.create_dataframe(trainlabels_df)\n",
    "\n",
    "train_labels.write.save_as_table(\"LABELS_TRAIN\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d57596",
   "metadata": {},
   "source": [
    "# Download Images \n",
    " Downloads image files from a Snowflake stage, encodes them in Base64, merges them with label data that was processed in the last step, and inserts the combined information into a Snowflake table named training_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_stage_path = \"@DATA_STAGE/images/\"\n",
    "\n",
    "\n",
    "local_train_images_dir = \"/tmp/images\"\n",
    "\n",
    "\n",
    "os.makedirs(local_train_images_dir, exist_ok=True)\n",
    "\n",
    "# Function to download images from Snowflake stage and convert them to Base64\n",
    "def download_images_from_stage(stage_path, local_dir):\n",
    "    # Use session.file.get() to fetch images\n",
    "    files = session.file.get(stage_path, local_dir)\n",
    "    \n",
    "    # List to hold the image data\n",
    "    images_data = []\n",
    "    \n",
    "    if files:\n",
    "        for file in files:\n",
    "            filename = os.path.basename(file.file)            \n",
    "            # Read the image and convert to Base64\n",
    "            with open(os.path.join(local_dir, filename), \"rb\") as image_file:\n",
    "                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "                images_data.append({\"Filename\": filename.replace(\".jpg\", \"\"), \"image_data\": encoded_string})\n",
    "    else:\n",
    "        print(f\"No image files were downloaded from {stage_path}.\")\n",
    "    \n",
    "    return images_data\n",
    "\n",
    "# Download the train and validation images and convert to Base64\n",
    "train_images_base64_data = download_images_from_stage(train_images_stage_path, local_train_images_dir)\n",
    "\n",
    "# Convert to DataFrames for inserting into separate tables\n",
    "train_images_df = pd.DataFrame(train_images_base64_data)\n",
    "\n",
    "\n",
    "if 'filename' in trainlabels_df.columns:\n",
    "    trainlabels_df.rename(columns={'filename': 'Filename'}, inplace=True)\n",
    "    #vallabels_df.rename(columns={'filename': 'Filename'}, inplace=True)\n",
    "\n",
    "merged_train_df = pd.merge(trainlabels_df, train_images_df, how='inner', on='Filename')\n",
    "\n",
    "\n",
    "# Merge the train_images_df with trainlabels_df on the Filename column\n",
    "merged_train_df = pd.merge(trainlabels_df, train_images_df, how='inner', on='Filename')\n",
    "\n",
    "# Create the Snowflake table schema to accommodate both image data and label information\n",
    "create_train_table_query = \"\"\"\n",
    "CREATE OR REPLACE TABLE training_data (\n",
    "    Filename INT,\n",
    "    image_data VARCHAR,\n",
    "    class INT,\n",
    "    xmin FLOAT,\n",
    "    ymin FLOAT,\n",
    "    xmax FLOAT,\n",
    "    ymax FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "# Execute the table creation query\n",
    "session.sql(create_train_table_query).collect()\n",
    "\n",
    "# Function to insert merged image and label data into the specified table\n",
    "def insert_images_and_labels_into_table(merged_df, table_name):\n",
    "    for index, row in merged_df.iterrows():\n",
    "        insert_query = f\"\"\"\n",
    "        INSERT INTO {table_name} (Filename, image_data, class, xmin, ymin, xmax, ymax)\n",
    "        VALUES ('{row['Filename']}', '{row['image_data']}', '{row['class']}', {row['xmin']}, {row['ymin']}, {row['xmax']}, {row['ymax']})\n",
    "        \"\"\"\n",
    "        \n",
    "        session.sql(insert_query).collect()\n",
    "\n",
    "# Insert merged data into the train table\n",
    "insert_images_and_labels_into_table(merged_train_df, \"training_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250bed13-6cfd-4ff5-bb59-84894d62c9c2",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "### View the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84721d-d9ba-44ed-b5db-db91fd69c382",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Dataset_sample"
   },
   "outputs": [],
   "source": [
    "session.table(\"training_data\").limit(5).collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afef197-07d0-41b5-b485-7f5fd32a0a63",
   "metadata": {
    "collapsed": false,
    "name": "Train_heading"
   },
   "source": [
    "# Training\n",
    "\n",
    "## Step 1: Define a Training Function for Each Worker\n",
    "\n",
    "Create a function that defines the training process for an individual worker. This function will be executed independently on each worker during distributed training.\n",
    "\n",
    "## Step 2: Execute the Training Function Using PyTorchDistributor\n",
    "\n",
    "Use the PyTorchDistributor to distribute and manage the execution of the training function across multiple workers.\n",
    "\n",
    "* The **ShardedDataConnector** ensures that the dataset is evenly partitioned (sharded) and distributed across all workers.\n",
    "* The **PyTorchScalingConfig** specifies the number of workers and necessary resources (e.g., CPUs, GPUs, memory) for each worker.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883e4b4-8058-4b36-82c1-cfde8ef54a26",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Train_function"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn  \n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor  \n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights \n",
    "import torch.distributed as dist\n",
    "from snowflake.ml.modeling.distributors.pytorch import get_context\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import tempfile\n",
    "import cloudpickle as cp\n",
    "\n",
    "def train_func():\n",
    "    context = get_context()\n",
    "    rank = context.get_rank()\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    print(f\"Worker Rank : {rank}, world_size: {context.get_world_size()}\")\n",
    "\n",
    "    ###\n",
    "    #  Wrapper to transform the dataset.\n",
    "    ###\n",
    "    class FCBData(IterableDataset):\n",
    "        def __init__(self, source_dataset, transforms=None):  \n",
    "            self.source_dataset = source_dataset\n",
    "            self.transforms = transforms if transforms else torchvision.transforms.ToTensor()  # Ensure we apply ToTensor transform\n",
    "    \n",
    "        def __iter__(self):\n",
    "            for row in self.source_dataset:\n",
    "                base64_image = row['IMAGE_DATA']\n",
    "                image = Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "                # Convert the image to a tensor\n",
    "                image = self.transforms(image)  # Converts PIL image to tensor\n",
    "    \n",
    "                # Extract bounding box and labels\n",
    "                boxes = [[row[k].item() for k in [\"XMIN\", \"YMIN\", \"XMAX\", \"YMAX\"]] for _ in range(1)]\n",
    "                labels = [row[\"CLASS\"].item()]\n",
    "    \n",
    "                boxes = torch.as_tensor(boxes, dtype=torch.float32)  \n",
    "                labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "                \n",
    "                # Prepare the target dictionary\n",
    "                target = {  \n",
    "                    'boxes': boxes,  \n",
    "                    'labels': labels,  \n",
    "                    'image_id': torch.tensor([int(row[\"FILENAME\"])]),\n",
    "                    'area': (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1]),  # Calculate area\n",
    "                    'iscrowd': torch.zeros((boxes.shape[0],), dtype=torch.uint8)  # Set iscrowd to 0 for all\n",
    "                }\n",
    "                yield (image, target)\n",
    "\n",
    "    with torch.cuda.device(rank):\n",
    "        # Model initialization\n",
    "        weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n",
    "        model = fasterrcnn_resnet50_fpn(weights=weights)\n",
    "          \n",
    "        # Modify the model for your number of classes (including background)\n",
    "        num_classes = 6  \n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features  \n",
    "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "        model.to(rank)\n",
    "        model = DDP(model, device_ids=[rank])\n",
    "        \n",
    "    \n",
    "        optimizer = torch.optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001, weight_decay=0.0005)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "        # Load the data using ShardedDataConnector\n",
    "        dataset_map = context.get_dataset_map()\n",
    "        train_shard = dataset_map[\"train\"].get_shard().to_torch_dataset()\n",
    "        train_dataset = FCBData(train_shard)\n",
    "    \n",
    "        # get hyper_params \n",
    "        hyper_parms = context.get_hyper_params()\n",
    "        \n",
    "        def collate_fn(batch):\n",
    "            return tuple(zip(*batch))\n",
    "    \n",
    "        batch_size = int(hyper_parms['batch_size'])\n",
    "        train_data_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            collate_fn=collate_fn,\n",
    "            pin_memory=True,\n",
    "            pin_memory_device=f\"cuda:{rank}\"\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        num_epochs = int(hyper_parms['num_epochs'])\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            running_batches = 0\n",
    "            for images, targets in train_data_loader:\n",
    "                running_batches = running_batches + 1\n",
    "                images = [image.float() / 255.0 for image in images]\n",
    "                images = [image.to(rank) for image in images]\n",
    "                targets = [{k: v.to(rank) for k, v in t.items()} for t in targets]\n",
    "                \n",
    "                loss_dict = model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values())\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                running_loss += losses.item()\n",
    "    \n",
    "            print(f\"[Rank {rank}] Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / (running_batches*batch_size):.4f}, Processed {running_batches * (epoch+1) * batch_size} images so far\")\n",
    "            lr_scheduler.step()\n",
    "    \n",
    "        MODEL_PATH = \"/tmp/models/detectionmodel.pt\"\n",
    "        if rank == 0:\n",
    "            with open(MODEL_PATH, mode=\"w+b\") as model_file:\n",
    "                    torch.save(model.module.state_dict(), model_file)\n",
    "            print(f\"Model written to {MODEL_PATH}\")\n",
    "    \n",
    "        print(f\"[Rank {rank}] Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a83929-ea61-4d1d-98a0-13637768a4dd",
   "metadata": {
    "collapsed": false,
    "name": "traindataset"
   },
   "source": [
    "### For the purpose of this quickstart, we have considered a smaller volume as the data source. But ideally this can scale million rows\n",
    "\n",
    "1. Split the dataset (shard) for distributed training across multiple workers.\n",
    "2. Train a PyTorch model using 4 workers, each utilizing 1 GPU for efficient computation. Control the training with hyperparameters such as batch size and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e1ca6-34ac-47b2-9e3a-8295712a99b5",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Train_dataset"
   },
   "outputs": [],
   "source": [
    "# Set up PyTorchDistributor\n",
    "from snowflake.ml.modeling.distributors.pytorch import PyTorchDistributor, PyTorchScalingConfig, WorkerResourceConfig  \n",
    "from snowflake.ml.data.sharded_data_connector import ShardedDataConnector  \n",
    "\n",
    "df = session.table(\"training_data\")\n",
    "\n",
    "# Create sharded data connector.\n",
    "train_data = ShardedDataConnector.from_dataframe(df)\n",
    "\n",
    "# Create pytorch distributor.\n",
    "pytorch_trainer = PyTorchDistributor(  \n",
    "    train_func=train_func,\n",
    "    scaling_config=PyTorchScalingConfig(  \n",
    "        num_nodes=1,  \n",
    "        num_workers_per_node=4,  \n",
    "        resource_requirements_per_worker=WorkerResourceConfig(num_cpus=0, num_gpus=1),  \n",
    "    )  \n",
    ")  \n",
    "\n",
    "# Run the trainer.\n",
    "pytorch_trainer.run(\n",
    "    dataset_map={\"train\": train_data},\n",
    "    hyper_params={\"batch_size\": \"32\", \"num_epochs\": \"5\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907a9df-75d9-4b1e-b65d-d7cd08b51c70",
   "metadata": {
    "collapsed": false,
    "name": "modeldeploy"
   },
   "source": [
    "# MODEL DEPLOYMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465650d2-213f-4dc1-ab29-39d8915d1756",
   "metadata": {
    "collapsed": false,
    "name": "modelreg"
   },
   "source": [
    "# Snowflake Model Registry - Securely manage models and their metadata in Snowflake.\n",
    "\n",
    "The model registry stores machine learning models as first-class schema-level objects in Snowflake.\n",
    "\n",
    "* Load the model produced by trainer \n",
    "* Define custom wrapper for the PyTorch model\n",
    "* Save it to Model Registry by specifying the model_name,version_name,input dataframe as signature and conda_dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0a785-ed92-4363-a6e2-bfbcc057adfb",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "logmodeltoregistry_customwrapper"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN_ResNet50_FPN_Weights\n",
    "from PIL import Image\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "df=session.table(\"VAL_IMAGES_LABELS\").limit(1).to_pandas()\n",
    "\n",
    "first_row = df.iloc[0]  \n",
    "base64_image = first_row['IMAGE_DATA'] \n",
    "df = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \n",
    "\n",
    "spdf=session.create_dataframe(df)\n",
    "# Function to load the model\n",
    "def load_model(model_path):  \n",
    "    weights = FasterRCNN_ResNet50_FPN_Weights.DEFAULT  \n",
    "    model = fasterrcnn_resnet50_fpn(weights=weights)  \n",
    "    \n",
    "    # Modify the box predictor for your specific dataset\n",
    "    num_classes = 6  # Background + 5 classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features  \n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)  \n",
    "    model.load_state_dict(torch.load(model_path), strict=False)  \n",
    "    model.double()\n",
    "    model.eval()  \n",
    "    return model  \n",
    "\n",
    "# Function to decode and transform an image\n",
    "def decode_and_transform_image(base64_image):  \n",
    "    image_data = base64.b64decode(base64_image)  \n",
    "    image = Image.open(io.BytesIO(image_data)).convert('RGB')  \n",
    "    if image.mode != 'RGB':\n",
    "        image = image.convert('RGB')\n",
    "    # Define the necessary transformations\n",
    "    transform = transforms.Compose([  \n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),  # Converts to [C, H, W]\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "    ])  \n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.double()\n",
    "    \n",
    "    # Debugging: Print the shape after transformation\n",
    "    print(f\"Shape after transformation: {image_tensor.shape}\")\n",
    "    \n",
    "    return image_tensor\n",
    "\n",
    "\n",
    "# try:\n",
    "model_path = '/tmp/models/detectionmodel.pt'\n",
    "model = load_model(model_path)\n",
    "\n",
    "from snowflake.ml.model import custom_model\n",
    "\n",
    "class DefectDetectionModel(custom_model.CustomModel):\n",
    "    def __init__(self, context: custom_model.ModelContext) -> None:\n",
    "        super().__init__(context)\n",
    "\n",
    "    @custom_model.inference_api\n",
    "    def predict(self, input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        processed_input = torch.stack(input_df['IMAGE_DATA'].apply(decode_and_transform_image).to_list())\n",
    "        raw_output = self.context.model_ref(\"rcnn\").forward(processed_input)\n",
    "        final_output = pd.DataFrame({\"output\": [json.dumps({k: v.detach().cpu().numpy().tolist() for k, v in res.items()}) for res in raw_output]})\n",
    "        return final_output\n",
    "\n",
    "ddm = DefectDetectionModel(context = custom_model.ModelContext(models={'rcnn': model}))\n",
    "\n",
    "\n",
    "ml_reg = Registry(session=session)  \n",
    "# Log the model with the sample input for Snowflake registry\n",
    "mv = ml_reg.log_model(  \n",
    "    ddm,  \n",
    "    model_name=\"DefectDetectionModel\",  \n",
    "    version_name='v3',  \n",
    "    sample_input_data=spdf,\n",
    "    conda_dependencies=[\"pytorch\", \"torchvision\"],\n",
    "    options={\"embed_local_ml_library\": True,\n",
    "             \n",
    "                \"relax\": True}\n",
    "\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240369f3-e766-453f-acbe-245c8d0a444f",
   "metadata": {
    "collapsed": false,
    "name": "mk3"
   },
   "source": [
    "## Fetch the logged Model from Snowflake Registry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d32ac1-da76-4f35-be25-46fd63747aee",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "registry_init"
   },
   "outputs": [],
   "source": [
    "# Usage Example\n",
    "reg = Registry(session=session) \n",
    "model_ref = reg.show_models()\n",
    "model_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb44e09-e1e1-42f5-9792-9a070713a310",
   "metadata": {
    "collapsed": false,
    "name": "mk4"
   },
   "source": [
    "## Detect Defects on Validation dataset\n",
    "Lets consider there is a validation table VAL_IMAGES_LABELS which contains the Base64 Encoding information of validation images.\n",
    "\n",
    "* Get a reference to a specific model from the registry by name using the registry’s get_model method\n",
    "* Get a reference to a specific version of a model as a ModelVersion instance using the model’s version method.\n",
    "* Carry inference using the model and output the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4235d30-0724-4d7b-875b-b7403fe933c3",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "perform_inference"
   },
   "outputs": [],
   "source": [
    "\n",
    "m = reg.get_model(\"DEFECTDETECTIONMODEL\")\n",
    "mv = m.version(\"GENTLE_DONKEY_4\")\n",
    "\n",
    "\n",
    "df=session.table(\"VAL_IMAGES_LABELS\").limit(1).to_pandas()\n",
    "\n",
    "first_row = df.iloc[0]\n",
    "base64_image = first_row['IMAGE_DATA'] \n",
    "image_data_df = pd.DataFrame({'IMAGE_DATA': [base64_image]})  \n",
    "image_data_df.head()\n",
    "\n",
    "\n",
    "\n",
    "remote_prediction = mv.run(image_data_df, function_name=\"predict\")\n",
    "remote_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1171d107-c228-4d7b-8cbb-d92469c83c69",
   "metadata": {
    "collapsed": false,
    "name": "displayimage"
   },
   "source": [
    "Fetch predictions and use a function display_image_with_boxes() to display Image with Bounding Boxes and Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92228f7-74bc-45fc-8c18-c8db544f919b",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "visualize_defects"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Class mapping dictionary\n",
    "classes_la = {\n",
    "    0: \"open\",\n",
    "    1: \"short\",\n",
    "    2: \"mousebite\",\n",
    "    3: \"spur\",\n",
    "    4: \"copper\",\n",
    "    5: \"pin-hole\"\n",
    "}\n",
    "\n",
    "# Function to display the image with bounding boxes and class labels\n",
    "def display_image_with_boxes(image, boxes, labels, scores, target_size=(800, 600)):\n",
    "    # Resize the image to a target size\n",
    "    img = image.resize(target_size).convert(\"RGB\")  # Resize and convert to RGB\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # Adjust the DPI and figure size\n",
    "    fig, ax = plt.subplots(figsize=(3, 6), dpi=10)  # Adjust figure size and DPI\n",
    "    ax.imshow(img_np)\n",
    "\n",
    "    for label, box, score in zip(labels, boxes, scores):\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        class_label = classes_la[label]\n",
    "\n",
    "        # Create a Rectangle patch\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        ax.text(xmin, ymin, f\"{class_label}: {score:.2f}\", verticalalignment='top', color='red', fontsize=13, weight='bold')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)  # Ensure no padding/margins around the image\n",
    "    plt.show()\n",
    "\n",
    "# Combine the image data and remote prediction DataFrames\n",
    "combined_df = pd.concat([image_data_df, remote_prediction], axis=1)\n",
    "\n",
    "# Create a list to store data for the final DataFrame\n",
    "rows = []\n",
    "\n",
    "# Iterate through each row in the combined DataFrame\n",
    "for index, row in combined_df.iterrows():\n",
    "    output_str = row.get('output', None)  # Get the output column value\n",
    "\n",
    "    if isinstance(output_str, str):  # Ensure it's a valid string before loading as JSON\n",
    "        try:\n",
    "            # Convert the 'output' column JSON string into a dictionary\n",
    "            output_data = json.loads(output_str)\n",
    "\n",
    "            # Extract boxes, labels, and scores from JSON data\n",
    "            if 'boxes' in output_data and 'labels' in output_data and 'scores' in output_data:\n",
    "                boxes = output_data['boxes']\n",
    "                labels = output_data['labels']\n",
    "                scores = output_data['scores']\n",
    "\n",
    "                # Decode the image data\n",
    "                image_data = base64.b64decode(row['IMAGE_DATA'])\n",
    "                image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "\n",
    "                # Limit to top 5 classes based on scores\n",
    "                if len(scores) > 0:\n",
    "                    # Create a DataFrame to manage boxes, labels, and scores\n",
    "                    data = pd.DataFrame({\n",
    "                        'box': boxes,\n",
    "                        'label': labels,\n",
    "                        'score': scores\n",
    "                    })\n",
    "\n",
    "                    # Get the top 5 entries based on scores\n",
    "                    top_classes = data.nlargest(5, 'score')\n",
    "\n",
    "                    # Extract corresponding boxes, labels, and scores\n",
    "                    top_boxes = top_classes['box'].tolist()\n",
    "                    top_labels = top_classes['label'].tolist()\n",
    "                    top_scores = top_classes['score'].tolist()\n",
    "\n",
    "                    # Store each of the top 5 predictions as a separate row\n",
    "                    for i in range(len(top_boxes)):\n",
    "                        rows.append({\n",
    "                            'image_data': row['IMAGE_DATA'],\n",
    "                            'output': row['output'],\n",
    "                            'label': top_labels[i],\n",
    "                            'box': top_boxes[i],\n",
    "                            'score': top_scores[i]\n",
    "                        })\n",
    "\n",
    "                    # Display the image with bounding boxes and labels\n",
    "                    display_image_with_boxes(image, top_boxes, top_labels, top_scores)\n",
    "                else:\n",
    "                    print(\"No scores available to limit to top 5.\")\n",
    "            else:\n",
    "                print(\"Missing keys 'boxes', 'labels', or 'scores' in the output data.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Invalid JSON in row {index}, skipping this row.\")\n",
    "    else:\n",
    "        print(f\"Invalid output type (not a string) in row {index}, skipping this row.\")\n",
    "\n",
    "# Create the final DataFrame with the collected rows (one row per label/box/score)\n",
    "final_df = pd.DataFrame(rows)\n",
    "session.sql(\"create TABLE if not exists PCB_DATASET.PUBLIC.DETECTION_OUTPUTS (\n",
    "\timage_data VARCHAR(16777216),\n",
    "\toutput VARCHAR(16777216),\n",
    "\tlabel NUMBER(38,0),\n",
    "\tbox VARIANT,\n",
    "\tscore FLOAT\n",
    ")\").collect()\n",
    "\n",
    "# Write the DataFrame to the Snowflake table\n",
    "combined_spdf = session.create_dataframe(final_df)\n",
    "combined_spdf.write.save_as_table(\"DETECTION_OUTPUTS\", mode=\"overwrite\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
