Metadata-Version: 2.1
Name: edg4llm
Version: 1.0.10
Summary: A unified tool to generate fine-tuning datasets for LLMs, including questions, answers, and dialogues.
Home-page: https://github.com/alannikos/edg4llm
Author: Alannikos
Author-email: alannikos768@outlook.com
Keywords: LLM fine-tuning data-generation AI NLP
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.32.3
Requires-Dist: pyfiglet>=0.7.6
Requires-Dist: termcolor>=2.0.0

# EDG4LLM

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Library Scope](#library-scope)
- [Quick Start](#quick-start)
- [Requirements](#requirements)
- [Development Setup](#development-setup)
- [Testing](#testing)
- [License](#license)
- [Security](#security)
- [Contributing](#contributing)

## Features

- Convert OpenAPI specifications into LLM-compatible tool/function definitions
- Support for multiple LLM providers (OpenAI, Anthropic, Cohere)
- Handle complex request bodies and parameter types
- Support for multiple authentication mechanisms
- Support for OpenAPI 3.0.x and 3.1.x specifications
- Handles both YAML and JSON OpenAPI specifications

## Installation

```bash
pip install openapi-llm
```

### Supported Python Versions
- Python >= 3.8

### LLM Provider Dependencies

This library focuses on OpenAPI-to-LLM conversion and doesn't include LLM provider libraries by default. Install the ones you need:

```bash
# For OpenAI
pip install openai

# For Anthropic
pip install anthropic

# For Cohere
pip install cohere
```

## Library Scope

OpenAPI-LLM provides core functionality for converting OpenAPI specifications into LLM-compatible tool/function definitions. It intentionally does not provide an opinionated, high-level interface for OpenAPI-LLM interactions. Users are encouraged to develop their own thin application layer above this library that suits their specific needs and preferences for OpenAPI-LLM integration.

### OpenAPI Specification Validation

This library does not perform OpenAPI specification validation. It is the user's responsibility to ensure that the provided OpenAPI specifications are valid. We recommend using established validation tools such as:

- [openapi-spec-validator](https://github.com/p1c2u/openapi-spec-validator)
- [prance](https://github.com/RonnyPfannschmidt/prance)
- [Swagger Editor](https://editor.swagger.io/)

Example of validating a spec before using it with openapi-llm:

```python
from openapi_spec_validator import validate_spec
import yaml

# Load and validate your OpenAPI spec
with open('your_spec.yaml', 'r') as f:
    spec_dict = yaml.safe_load(f)
validate_spec(spec_dict)
```

## Quick Start

Here's a practical example using OpenAI to perform a Google search via SerperDev API:

```python
import os
from openai import OpenAI

from openapi_llm.client.config import ClientConfig
from openapi_llm.client.openapi import OpenAPIClient
from openapi_llm.core.spec import OpenAPISpecification


# Configure the OpenAPI client with SerperDev API spec and credentials
config = ClientConfig(
    openapi_spec=OpenAPISpecification.from_url("https://bit.ly/serperdev_openapi"), 
    credentials=os.getenv("SERPERDEV_API_KEY")
)

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Create a chat completion with tool definitions
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{"role": "user", "content": "Do a serperdev google search: Who was Nikola Tesla?"}],
    tools=config.get_tool_definitions(),
)

# Execute the API call based on the LLM's response
service_api = OpenAPIClient(config)
service_response = service_api.invoke(response)
```

This example demonstrates:
- Loading an OpenAPI specification from a URL
- Integrating with OpenAI's function calling
- Handling API authentication
- Converting and executing OpenAPI calls based on LLM responses

## Requirements

- Python >= 3.8
- Dependencies:
  - jsonref
  - requests
  - PyYAML

## Development Setup

1. Clone the repository

```bash
git clone https://github.com/vblagoje/openapi-llm.git
```

2. Install hatch if you haven't already

```bash
pip install hatch
```

3. Install pre-commit hooks

```bash
pre-commit install
```

4. Install desired LLM provider dependencies (as needed)

```bash
pip install openai anthropic cohere
```

## Testing

Run tests using hatch:

```bash
# Unit tests
hatch run test:unit

# Integration tests
hatch run test:integration

# Type checking
hatch run test:typing

# Linting
hatch run test:lint
```

## License

MIT License - See [LICENSE](LICENSE) for details.

## Security

For security concerns, please see our [Security Policy](SECURITY.md).

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## Author
Vladimir Blagojevic (dovlex@gmail.com)

Reviews and guidance by Madeesh Kannan
