Metadata-Version: 2.1
Name: langchain-turbopuffer
Version: 0.1.0
Summary: 
Author: Alex Chi Z
Author-email: iskyzh@gmail.com
Requires-Python: >=3.10,<3.13
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: langchain (>=0.3.14,<0.4.0)
Requires-Dist: turbopuffer[fast] (>=0.1.25,<0.2.0)
Description-Content-Type: text/markdown

# langchain-turbopuffer

Use Turbopuffer as a vector store for LangChain.

## Usage

```bash
poetry add git+https://github.com/skyzh/langchain-turbopuffer
# see example.py for usage
```

```python
from langchain_turbopuffer import TurbopufferVectorStore

vectorstore = TurbopufferVectorStore(
    embedding=OllamaEmbeddings(model="mxbai-embed-large"),
    namespace="langchain-turbopuffer-test",
    api_key=os.getenv("TURBOPUFFER_API_KEY"),
)
```

## Local Development

```bash
git clone https://github.com/skyzh/langchain-turbopuffer
cd langchain-turbopuffer
poetry env use 3.12
poetry install

ollama pull mxbai-embed-large llama3.2
ollama run llama3.2
export TURBOPUFFER_API_KEY=your_api_key
poetry run python example.py
poetry run python example.py --skip-load
```

In the example, you can ask questions like "What is prompt engineering?"

## License

MIT

Note that the `example.py` is from [langchain-risinglight](https://github.com/skyzh/langchain-risinglight) based on several online tutorials (see the file header for more details).

