from MLTask_utils.Utils.AudioUtils import split_mp3_by_size
from pprint import pprint
from openai import OpenAI, NotGiven
from openai.types.chat import ChatCompletionMessageParam
from typing import List


# def list_models():
#     print(openai.Model.list())


def do_speak(targe_file_path, text_to_speak, model_name="tts-1", voice="alloy", response_format="mp3", speed=1):
    """
        Generate speech using OpenAI and save it to a file.

        :param target_file_path: Path to save the generated speech.
        :param model_name: The name of the model to use.
        :param voice: The voice to use for speech generation. Valid values are 'alloy', 'echo', 'fable', 'onyx', 'nova', and 'shimmer'.
        :param response_format: The format of the generated speech.
        :param speed: The speed of speech generation.
        :param text_to_speak: The text to be converted to speech.
    """
    client = OpenAI()
    with client.audio.speech.with_streaming_response.create(
        model=model_name,
        voice=voice,
        input=text_to_speak,
        response_format=response_format,
        speed=speed
    ) as response:
        response.stream_to_file(targe_file_path)

    return targe_file_path


def do_transcribe(audio_file_path, model_name="whisper-1", temperature=None, prompt=None, language=None, response_format="json"):
    client = OpenAI()
    file_chunks = split_mp3_by_size(audio_file_path)
    transcript_text = ""
    for file_chunk in file_chunks:
        audio_file = open(file_chunk, "rb")
        temperature = 0 if temperature == None else temperature
        print(f"about to transcribe chunk {file_chunk}")
        transcript = client.audio.transcriptions.create(
            model=model_name, file=audio_file, temperature=temperature, prompt=prompt, language=language, response_format=response_format)

    # response_format='verbose_json' # this gives the segments :)
        transcript_text += transcript.text
        print(f"ffinished transcribing chunk {file_chunk}")
        print("======")
    print("all done here returning text")
    return transcript_text


def do_transcribe_to_file(audio_file_path, model_name="whisper-1", temperature=None, prompt=None, language=None, output_path='src/MLTasks/OpenAI', filename='transcript.txt'):
    transcript_text = do_transcribe(
        audio_file_path, model_name, temperature, prompt, language)
    transcript_file = open(f"{output_path}/{filename}", "a")
    transcript_file.write(transcript_text)
    transcript_file.close()
    return transcript_file


def do_chat(messages: List[ChatCompletionMessageParam], model, n=None, temperature=None, top_p=None, presence_penalty=None, frequency_penalty=None, max_tokens=8000):
    """
    Perform a chat-based interaction with the OpenAI GPT-3.5 language model.

    Parameters:
        messages (list): A list of dictionaries representing the conversation messages.
            Each dictionary should have keys 'role' and 'content'.
            'role' (str): The role of the message sender. Allowed values are 'system', 'assistant', and 'user'.
            'content' (str): The content of the message sent by the sender.
        model (str): The name or ID of the model to use.

    Returns:
        completion (dict): The response generated by the language model.

    Raises:
        OpenAIException: If an error occurs while making the API request.

    Usage:
        conversation = [
            {"role": "user", "content": "Hello, how are you?"},
            {"role": "assistant", "content": "I'm doing well. How can I assist you today?"}
        ]
        response = do_chat(messages=conversation)
    """

    n = n or 1
    temperature = temperature or 1
    top_p = top_p or 1
    presence_penalty = presence_penalty or 0
    frequency_penalty = frequency_penalty or 0
    client = OpenAI()
    completion = client.chat.completions.create(
        model=model,
        messages=messages,
        n=n,
        temperature=temperature,
        top_p=top_p,
        presence_penalty=presence_penalty,
        frequency_penalty=frequency_penalty,
        max_tokens=max_tokens
        # logit_bias
        # response_format
    )
    # print("got back result")
    # print(completion)
    return completion.choices


def do_chat_4_vision(messages: List[ChatCompletionMessageParam], n=None, temperature=None, top_p=None, presence_penalty=None, frequency_penalty=None):
    return do_chat(messages, "gpt-4-vision-preview", n, temperature, top_p, presence_penalty, frequency_penalty, max_tokens=4096)


def do_chat_4_with_model(model, messages: List[ChatCompletionMessageParam], n=None, temperature=None, top_p=None, presence_penalty=None, frequency_penalty=None):
    return do_chat(messages, model, n, temperature, top_p, presence_penalty, frequency_penalty, max_tokens=4095)


def do_chat_3_5_TURBO(messages: List[ChatCompletionMessageParam], n=None, temperature=None, top_p=None, presence_penalty=None, frequency_penalty=None):
    return do_chat(messages, "gpt-3.5-turbo", n, temperature, top_p, presence_penalty, frequency_penalty)


def generate_image_from_text(prompt, model="dall-e-2", n=1, size="1024x1024", quality="standard", style="vivid"):
    client = OpenAI()
    response = client.images.generate(
        model=model,
        quality=quality,
        prompt=prompt, n=n, size=size, style=style
    )
    pprint(response)
    return response


def generate_image_variation(source_image_path, n=1, size="1024x1024"):
    client = OpenAI()
    response = client.images.create_variation(
        image=open(source_image_path, "rb"),
        n=n, size=size
    )
    pprint(response)
    return response


def edit_image_with_mask(source_image_path, edit_instructions, mask_image_path=None, n=1, size="1024x1024"):
    image_args = {
        "image": open(source_image_path, "rb"),
        "prompt": edit_instructions,
        "n": n,
        "size": size
    }

    if mask_image_path is not None:
        image_args["mask"] = open(mask_image_path, "rb")
    client = OpenAI()
    response = client.images.edit(**image_args)
    pprint(response)
    return response
