{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): singledispatch in /usr/local/lib/python3.5/dist-packages (from nltk)\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /usr/lib/python3/dist-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOPICS = 20\n",
    "MAX_TERMS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')).union({\n",
    "    'introduction', 'edition', 'series', 'application',\n",
    "    'approach', 'card', 'access', 'package', 'plus', 'etext',\n",
    "    'brief', 'vol', 'fundamental', 'guide', 'essential', 'printed',\n",
    "    'third', 'second', 'fourth'})\n",
    "\n",
    "sc = SparkContext('local', 'nlp')\n",
    "lines = sc.textFile('all_book_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines \\\n",
    "    .map(lambda line: line.strip().lower()) \\\n",
    "    .map(lambda line: line.split()) \\\n",
    "    .map(lambda words: [w for w in words if w.isalpha()]) \\\n",
    "    .map(lambda words: [w for w in words if len(w) > 3]) \\\n",
    "    .map(lambda words: [w for w in words if w not in stopwords]) \\\n",
    "    .zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = SparkSession.builder.appName('nlp').getOrCreate()\n",
    "df = sess.createDataFrame(lines, ['words', 'idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(words=['philosophy', 'love', 'reader'], idx=0),\n",
       " Row(words=['readings', 'islam'], idx=1),\n",
       " Row(words=['microprocessors', 'principles', 'applications'], idx=2),\n",
       " Row(words=['bernhard', 'edouard', 'story', 'north', 'american', 'forestry'], idx=3),\n",
       " Row(words=['encyclopedia', 'buddhism'], idx=4)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol='words',\n",
    "                     outputCol='tf')\n",
    "cv = cv.fit(df)\n",
    "df = cv.transform(df)\n",
    "df = IDF(inputCol='tf',\n",
    "         outputCol='tfidf').fit(df).transform(df)\n",
    "\n",
    "lda = LDA(k=N_TOPICS,\n",
    "          featuresCol='tfidf',\n",
    "          optimizer='em').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: probability statistics physics engineers game\n",
      "Topic 2: accounting ethics practice studies advanced\n",
      "Topic 3: language natural processing care information\n",
      "Topic 4: perspective theater text essentials states\n",
      "Topic 5: computer political organization architecture society\n",
      "Topic 6: physical philosophy pharmacology readings nursing\n",
      "Topic 7: understanding study pathophysiology literature judaism\n",
      "Topic 8: anthropology geology version programming using\n",
      "Topic 9: basic history evolution feminism concise\n",
      "Topic 10: life science handbook practical medicine\n",
      "Topic 11: history foundations sociology ecology earth\n",
      "Topic 12: methods global learning marketing research\n",
      "Topic 13: design real laboratory analysis finance\n",
      "Topic 14: financial business security managerial relativity\n",
      "Topic 15: mechanics engineering international structures quantum\n",
      "Topic 16: manual student actuarial american solutions\n",
      "Topic 17: buddhism writing networks microprocessor microbiology\n",
      "Topic 18: asian east early molecular social\n",
      "Topic 19: differential equations systems integrated elementary\n",
      "Topic 20: forensic anatomy physiology human course\n"
     ]
    }
   ],
   "source": [
    "for i, indices in enumerate(lda.describeTopics(MAX_TERMS).toPandas().termIndices):\n",
    "    print('Topic %d:'%(i+1), ' '.join([cv.vocabulary[idx] for idx in indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
