{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): tqdm in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): dill in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm requests dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def download_from_url(url, dst):\n",
    "    file_size = int(requests.head(url).headers[\"Content-Length\"])\n",
    "    if os.path.exists(dst):\n",
    "        first_byte = os.path.getsize(dst)\n",
    "    else:\n",
    "        first_byte = 0\n",
    "    if first_byte >= file_size:\n",
    "        return file_size\n",
    "    header = {\"Range\": \"bytes=%s-%s\" % (first_byte, file_size)}\n",
    "    pbar = tqdm(\n",
    "        total=file_size, initial=first_byte,\n",
    "        unit='B', unit_scale=True, desc=url.split('/')[-1])\n",
    "    req = requests.get(url, headers=header, stream=True)\n",
    "    with(open(dst, 'ab')) as f:\n",
    "        for chunk in req.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                pbar.update(1024)\n",
    "    pbar.close()\n",
    "    return file_size\n",
    "\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_from_url('http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz', \n",
    "                  'fashion/train-images-idx3-ubyte.gz')\n",
    "download_from_url('http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz', \n",
    "                  'fashion/train-labels-idx3-ubyte.gz')\n",
    "\n",
    "download_from_url('http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz', \n",
    "                  'fashion/t10k-images-idx3-ubyte.gz')\n",
    "download_from_url('http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz', \n",
    "                  'fashion/t10k-labels-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_mnist('fashion', kind='train')\n",
    "X_test, y_test = load_mnist('fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "df_train = map(lambda i: (int(y_train[i]), Vectors.dense(X_train[i])), range(len(X_train)))\n",
    "df_test = map(lambda i: (int(y_test[i]), Vectors.dense(X_test[i])), range(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder \\\n",
    "        .appName(\"examples\") \\\n",
    "        .master('local[4]').config('spark.driver.memory', '8g') \\\n",
    "        .getOrCreate()\n",
    "df_train = sparkSession.createDataFrame(df_train,schema=[\"labels\", \"features\"])\n",
    "df_test = sparkSession.createDataFrame(df_test,schema=[\"labels\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "import inception_v1\n",
    "\n",
    "def inception():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y = tf.placeholder(tf.int32, shape=[None, 1], name='y')\n",
    "    y = tf.reshape(y, [-1])\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    x = tf.image.grayscale_to_rgb(x)\n",
    "    x = tf.image.resize_images(x, (224, 224))\n",
    "    with slim.arg_scope(inception_v1.inception_v1_arg_scope()):\n",
    "        logits, endpoints = inception_v1.inception_v1(\n",
    "            x, num_classes = 10, is_training = True)\n",
    "    z = tf.argmax(logits, 1, name='out')\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(y,logits)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkflow.graph_utils import build_graph\n",
    "from sparkflow.tensorflow_async import SparkAsyncDL\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from sparkflow.graph_utils import build_adam_config\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "mg = build_graph(inception)\n",
    "adam_config = build_adam_config(learning_rate=0.001, beta1=0.9, beta2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_model = SparkAsyncDL(\n",
    "    inputCol='features',\n",
    "    tensorflowGraph=mg,\n",
    "    tfInput='x:0',\n",
    "    tfLabel='y:0',\n",
    "    tfOutput='out:0',\n",
    "    tfOptimizer='adam',\n",
    "    miniBatchSize=16,\n",
    "    miniStochasticIters=1,\n",
    "    shufflePerIter=True,\n",
    "    iters=10,\n",
    "    predictionCol='predicted',\n",
    "    labelCol='labels',\n",
    "    partitions=3,\n",
    "    verbose=1,\n",
    "    optimizerOptions=adam_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"sparkflow.HogwildSparkModel\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "fitted_model = spark_model.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is probably took a very long time\n",
    "\n",
    "![alt text](my-cpu.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
