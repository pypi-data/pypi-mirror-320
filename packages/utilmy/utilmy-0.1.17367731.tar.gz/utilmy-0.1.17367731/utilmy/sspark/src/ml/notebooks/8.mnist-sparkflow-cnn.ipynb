{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): tqdm in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): dill in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): idna<2.9,>=2.5 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "Requirement already satisfied (use --upgrade to upgrade): certifi>=2017.4.17 in /usr/local/lib/python3.5/dist-packages (from requests)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tqdm requests dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def download_from_url(url, dst):\n",
    "    file_size = int(requests.head(url).headers[\"Content-Length\"])\n",
    "    if os.path.exists(dst):\n",
    "        first_byte = os.path.getsize(dst)\n",
    "    else:\n",
    "        first_byte = 0\n",
    "    if first_byte >= file_size:\n",
    "        return file_size\n",
    "    header = {\"Range\": \"bytes=%s-%s\" % (first_byte, file_size)}\n",
    "    pbar = tqdm(\n",
    "        total=file_size, initial=first_byte,\n",
    "        unit='B', unit_scale=True, desc=url.split('/')[-1])\n",
    "    req = requests.get(url, headers=header, stream=True)\n",
    "    with(open(dst, 'ab')) as f:\n",
    "        for chunk in req.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                pbar.update(1024)\n",
    "    pbar.close()\n",
    "    return file_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115034"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_from_url('https://raw.githubusercontent.com/sjwhitworth/golearn/master/examples/datasets/mnist_train.csv', \n",
    "                  'mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparkflow.graph_utils import build_graph\n",
    "from sparkflow.tensorflow_async import SparkAsyncDL\n",
    "import tensorflow as tf\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from sparkflow.graph_utils import build_adam_config\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "    \n",
    "def cnn_model():\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x')\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name='y')\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "    conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "    conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "    fc1 = tf.contrib.layers.flatten(conv2)\n",
    "    out = tf.layers.dense(fc1, 10)\n",
    "    z = tf.argmax(out, 1, name='out')\n",
    "    loss = tf.losses.softmax_cross_entropy(y, out)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import rand\n",
    "sparkSession = SparkSession.builder.appName(\"csv\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkSession.read.csv('mnist_train.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=df.columns[1:785], outputCol='features').transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|label|\n",
      "+-----+\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va.select('label').show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = OneHotEncoder(inputCol='label', outputCol='labels', dropLast=False).transform(va).select(['features', 'label', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = build_graph(cnn_model)\n",
    "adam_config = build_adam_config(learning_rate=0.001, beta1=0.9, beta2=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_model = SparkAsyncDL(\n",
    "    inputCol='features',\n",
    "    tensorflowGraph=mg,\n",
    "    tfInput='x:0',\n",
    "    tfLabel='y:0',\n",
    "    tfOutput='out:0',\n",
    "    tfOptimizer='adam',\n",
    "    miniBatchSize=300,\n",
    "    miniStochasticIters=1,\n",
    "    shufflePerIter=True,\n",
    "    iters=50,\n",
    "    predictionCol='predicted',\n",
    "    labelCol='labels',\n",
    "    partitions=3,\n",
    "    verbose=1,\n",
    "    optimizerOptions=adam_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"sparkflow.HogwildSparkModel\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "fitted_model = spark_model.fit(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = fitted_model.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+---------+\n",
      "|            features|label|        labels|predicted|\n",
      "+--------------------+-----+--------------+---------+\n",
      "|(784,[132,133,134...|    1|(10,[1],[1.0])|      1.0|\n",
      "+--------------------+-----+--------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0264\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"predicted\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
