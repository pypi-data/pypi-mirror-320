"""  Utilities to manage experiments


"""
import warnings
warnings.filterwarnings("ignore")

import os, json, pandas as pd, numpy as np, copy
from types import SimpleNamespace
from typing import List, Dict
from box import Box

from utilmy import (pd_read_file, os_makedirs, pd_to_file, date_now, glob_glob, config_load,
                    json_save, json_load,)
from utilmy import log, log2
from utilmy import dict_merge_into




def exp_create_exp_folder(task="ner_deberta", dirout="./ztmp/exp", cc=None):
    """Create an experiment folder with a timestamped directory name and save   configuration object as a JSON file.
    Args:
        task (str, optional):   name of   task. Defaults to "ner_deberta".
        dirout (str, optional):   output directory. Defaults to "./ztmp/exp".
        cc (Box, optional):   configuration object. Defaults to None.
    """
    dt = date_now(fmt="%y%m%d/%H%M%S")
    dirout0   = dirout
    n_train   = cc.n_train
    cc.dirout = f"{dirout0}/{dt}-{task}-{n_train}"
    os_makedirs(cc.dirout)
    json_save({"cc": cc }, f"{dirout}/exp-{task}.json")
    return cc


def exp_config_override(cc, cfg0, cfg, cfg_name:str="ner_deberta"):
    cc.cfg      = cfg
    cc.cfg_name = cfg_name    
    if isinstance(cfg0, dict):
       log(f"###### Overide by config {cfg_name} ####################") 
       cc = dict_merge_into( cc.to_dict(), copy.deepcopy(cfg0),   )
       cc = Box(cc)

    log(cc.to_dict())
    return cc



def exp_get_filelist(dirdata):
  if "*" in dirdata.split("/")[-1] or "." in dirdata.split("/")[-1]  :
      flist = glob_glob(dirdata)      
  else:   
      flist = glob_glob(dirdata + "/*.parquet")
      flist = flist + glob_glob(dirdata + "/*.csv")
  log("nFiles: ", len(flist))
  return flist




def pd_add_textid(df, coltext="text", colid="text_id"):
    df[colid] = df[coltext].apply(lambda x : hash_textid(x) )
    return df


def hash_textid(xstr:str, n_chars=1000, seed=123):
    """Generate a UNIQUE hash value for a given text string.

       2 same Exact texts with different lengths --> 2 different hash values.


    Args:
        xstr (str): The input text string.
        n_chars (int, optional): The number of characters to consider from the input string. Defaults to 1000.
        seed (int, optional): The seed value for the hash function. Defaults to 123.

    Returns:
        int: The hash value generated by the xxhash.xxh64_intdigest function.

    Example:
        >>> hash_textid("example_text")
        123456789
    """
    import xxhash  
    xstr = str(xstr).strip()[:n_chars]
    unique_hash_per_text= xxhash.xxh64_intdigest(xstr, seed=seed) - len(xstr)
    return unique_hash_per_text





def hash_textid_minhash(s, num_hashes=4):
    """  Minhas for similarity compute --> Merge them together to have single hash
        # Example usage
        string1 = "hello"
        string2 = "hallo"

        hash1 = minhash_64bit(string1)
        hash2 = minhash_64bit(string2)

        print(hash1)
        print(hash2)

    """
    import hashlib
    import numpy as np

    # Generate a list of hash functions
    hash_funcs = [lambda x, i=i: int(hashlib.md5((str(i) + x).encode()).hexdigest(), 16) for i in range(num_hashes)]
    
    # Apply each hash function to the string and take the minimum value
    min_hashes = [min(hash_func(char) for char in s) for hash_func in hash_funcs]
    
    # Combine the min_hashes into a single 64-bit integer
    single_hash = np.int64(0)
    for h in min_hashes:
        single_hash ^= np.int64(h)
    
    return single_hash



def log_pd(*dfs:pd.DataFrame):
    for df in dfs:
      log( df.shape, "\n", list(df.columns))

