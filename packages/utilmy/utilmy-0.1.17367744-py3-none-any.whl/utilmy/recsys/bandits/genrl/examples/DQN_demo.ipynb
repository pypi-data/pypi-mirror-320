{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenRL_DQN_Video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/threewisemonkeys-as/genrl/blob/master/examples/DQN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOkJToH0asLB",
        "colab_type": "text"
      },
      "source": [
        "# Examples with DQN from GenRL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SATMNIdaxZi",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7AIp66ky69_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3a3f18e4-572f-4069-80de-ead359bf240e"
      },
      "source": [
        "!git clone https://github.com/SforAiDl/genrl\n",
        "!pip install -e genrl"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'genrl' already exists and is not an empty directory.\n",
            "Obtaining file:///content/genrl\n",
            "Requirement already satisfied: atari-py==0.2.6 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (0.2.6)\n",
            "Requirement already satisfied: box2d-py==2.3.8 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (2.3.8)\n",
            "Requirement already satisfied: certifi==2019.11.28 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (2019.11.28)\n",
            "Requirement already satisfied: cloudpickle==1.3.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: future==0.18.2 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (0.18.2)\n",
            "Requirement already satisfied: gym==0.17.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (0.17.1)\n",
            "Requirement already satisfied: numpy==1.18.2 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.18.2)\n",
            "Requirement already satisfied: opencv-python==4.2.0.34 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (4.2.0.34)\n",
            "Requirement already satisfied: pandas==1.0.4 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.0.4)\n",
            "Requirement already satisfied: Pillow==7.1.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (7.1.0)\n",
            "Requirement already satisfied: pyglet==1.5.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: six==1.14.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.14.0)\n",
            "Requirement already satisfied: matplotlib==3.2.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (3.2.1)\n",
            "Requirement already satisfied: pytest==5.4.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (5.4.1)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: torchvision==0.5.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (0.5.0)\n",
            "Requirement already satisfied: tensorflow-tensorboard==1.5.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.5.1)\n",
            "Requirement already satisfied: tensorboard==1.15.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: pre-commit==2.4.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: importlib-resources==1.0.1 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: setuptools==41.0.0 in /usr/local/lib/python3.6/dist-packages (from genrl==0.0.1) (41.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.4->genrl==0.0.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==1.0.4->genrl==0.0.1) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->genrl==0.0.1) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->genrl==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==3.2.1->genrl==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (1.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (0.2.5)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (8.4.0)\n",
            "Requirement already satisfied: pluggy<1.0,>=0.12 in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (0.13.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (20.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest==5.4.1->genrl==0.0.1) (20.1.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (0.35.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard==1.5.1->genrl==0.0.1) (0.9999999)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->genrl==0.0.1) (1.31.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.15.0->genrl==0.0.1) (0.8.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (0.10.1)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (1.5.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (1.4.29)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (5.3.1)\n",
            "Requirement already satisfied: virtualenv>=20.0.8 in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (20.0.31)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from pre-commit==2.4.0->genrl==0.0.1) (3.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest==5.4.1->genrl==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: filelock<4,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from virtualenv>=20.0.8->pre-commit==2.4.0->genrl==0.0.1) (3.0.12)\n",
            "Requirement already satisfied: appdirs<2,>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from virtualenv>=20.0.8->pre-commit==2.4.0->genrl==0.0.1) (1.4.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from virtualenv>=20.0.8->pre-commit==2.4.0->genrl==0.0.1) (0.3.1)\n",
            "Installing collected packages: genrl\n",
            "  Found existing installation: genrl 0.0.1\n",
            "    Can't uninstall 'genrl'. No files were found to uninstall.\n",
            "  Running setup.py develop for genrl\n",
            "Successfully installed genrl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_6SWFJ6HqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "from genrl.agents import DQN\n",
        "from genrl.agents.deep.dqn.utils import ddqn_q_target, prioritized_q_loss\n",
        "from genrl.environments import VectorEnv\n",
        "from genrl.trainers import OffPolicyTrainer, OnPolicyTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2zEFSI4a_XC",
        "colab_type": "text"
      },
      "source": [
        "## Training Vanilla DQN on CartPole "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHynQcDV6JMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "99e7a567-a358-4745-c561-0fbf4a2fcdf0"
      },
      "source": [
        "env = VectorEnv(\"CartPole-v0\")\n",
        "agent = DQN(\"mlp\", env)\n",
        "trainer = OffPolicyTrainer(agent, env, max_timesteps=20000)\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "timestep         Episode          value_loss       epsilon          Episode Reward   \n",
            "44               0.0              0                0.9785           0                \n",
            "240              10.0             0                0.8695           20.1             \n",
            "450              20.0             0                0.7117           23.0             \n",
            "734              30.0             0                0.559            28.2             \n",
            "930              40.0             0                0.4411           19.8             \n",
            "1120             50.0             0.3117           0.3654           19.4             \n",
            "1226             60.0             0.5066           0.3162           10.6             \n",
            "1466             70.0             0.9103           0.268            14.4             \n",
            "3290             80.0             2.2416           0.115            156.9            \n",
            "5290             90.0             9.0437           0.0259           200.0            \n",
            "7288             100.0            21.788           0.0122           200.0            \n",
            "9234             110.0            20.1689          0.0103           194.4            \n",
            "11234            120.0            18.4776          0.01             200.0            \n",
            "13234            130.0            16.0524          0.01             200.0            \n",
            "15234            140.0            9.4094           0.01             200.0            \n",
            "17234            150.0            6.919            0.01             200.0            \n",
            "19086            160.0            10.4121          0.01             192.6            \n",
            "Evaluated for 50 episodes, Mean Reward: 200.0, Std Deviation for the Reward: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaCoR9jTbFyE",
        "colab_type": "text"
      },
      "source": [
        "## Extending DQN to Double DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8xXyd8nZafc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DoubleDQN(DQN):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(DoubleDQN, self).__init__(*args, **kwargs)\n",
        "        self._create_model()\n",
        "\n",
        "    def get_target_q_values(self, next_states, rewards, dones):\n",
        "        next_q_value_dist = self.model(next_states)\n",
        "        next_best_actions = torch.argmax(next_q_value_dist, dim=-1).unsqueeze(-1)\n",
        "        rewards, dones = rewards.unsqueeze(-1), dones.unsqueeze(-1)\n",
        "        next_q_target_value_dist = self.target_model(next_states)\n",
        "        max_next_q_target_values = next_q_target_value_dist.gather(2, next_best_actions)\n",
        "        target_q_values = rewards + agent.gamma * torch.mul(\n",
        "            max_next_q_target_values, (1 - dones)\n",
        "        )\n",
        "        return target_q_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DCdOVBfZhuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "2edcb444-1daa-43da-b89c-c42c78224ab7"
      },
      "source": [
        "env = VectorEnv(\"CartPole-v0\")\n",
        "agent = DoubleDQN(\"mlp\", env)\n",
        "trainer = OffPolicyTrainer(agent, env, max_timesteps=20000)\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "timestep         Episode          value_loss       epsilon          Episode Reward   \n",
            "26               0.0              0                0.9872           0                \n",
            "238              10.0             0                0.8783           19.6             \n",
            "404              20.0             0                0.7283           19.1             \n",
            "644              30.0             0                0.597            20.1             \n",
            "842              40.0             0                0.4812           23.1             \n",
            "1054             50.0             0.3035           0.394            16.5             \n",
            "1158             60.0             0.4897           0.3374           16.4             \n",
            "1288             70.0             0.7634           0.3013           12.8             \n",
            "2686             80.0             2.1095           0.1569           101.9            \n",
            "4610             90.0             9.0553           0.0399           197.3            \n",
            "6372             100.0            19.4667          0.0146           185.1            \n",
            "8002             110.0            24.2586          0.0108           166.4            \n",
            "9420             120.0            22.9694          0.0102           144.4            \n",
            "11102            130.0            16.2487          0.01             162.7            \n",
            "12702            140.0            8.8523           0.01             169.4            \n",
            "14316            150.0            5.8546           0.01             151.1            \n",
            "15550            160.0            7.8662           0.01             132.7            \n",
            "17304            170.0            7.644            0.01             170.5            \n",
            "19274            180.0            12.3485          0.01             192.9            \n",
            "Evaluated for 50 episodes, Mean Reward: 200.0, Std Deviation for the Reward: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB9b1ENnbSU4",
        "colab_type": "text"
      },
      "source": [
        "## Extending DQN to Duelling DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mveQ_7TZZj3a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DuelingDQN(DQN):\n",
        "    def __init__(self, *args, buffer_type=\"push\", **kwargs):\n",
        "        super(DuelingDQN, self).__init__(*args, buffer_type=buffer_type, **kwargs)\n",
        "        self.dqn_type = \"dueling\"  # can be \"noisy\" for NoisyDQN\n",
        "        self._create_model()\n",
        "\n",
        "    def get_target_q_values(self, *args):\n",
        "        return ddqn_q_target(self, *args)\n",
        "    \n",
        "    # Prioritized Loss function needs to be imported only if buffer_type is set as prioritized\n",
        "    def get_q_loss(self, *args):\n",
        "        return prioritized_q_loss(self, *args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulUF5KppaNrF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "febf6c38-6ba9-486e-f1c8-fd4b921c74ab"
      },
      "source": [
        "env = VectorEnv(\"CartPole-v0\")\n",
        "agent = DuelingDQN(\"mlp\", env, buffer_type=\"prioritized\")\n",
        "trainer = OffPolicyTrainer(agent, env, max_timesteps=20000)\n",
        "trainer.train()\n",
        "trainer.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "timestep         Episode          value_loss       epsilon          Episode Reward   \n",
            "24               0.0              0                0.9882           0                \n",
            "182              10.0             0                0.9031           16.4             \n",
            "392              20.0             0                0.7536           20.8             \n",
            "568              30.0             0                0.6228           17.7             \n",
            "764              40.0             0                0.5189           18.8             \n",
            "1026             50.0             0.6067           0.4153           26.6             \n",
            "1172             60.0             0.4115           0.3398           14.5             \n",
            "1282             70.0             0.3327           0.3001           11.8             \n",
            "1524             80.0             0.3231           0.2538           18.3             \n",
            "2684             90.0             0.2799           0.1375           84.5             \n",
            "3830             100.0            0.5504           0.0502           140.3            \n",
            "5322             110.0            1.15             0.0212           143.5            \n",
            "6916             120.0            2.085            0.0124           151.1            \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}