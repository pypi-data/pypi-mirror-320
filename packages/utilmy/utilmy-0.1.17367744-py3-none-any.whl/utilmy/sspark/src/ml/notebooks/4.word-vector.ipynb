{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): nltk in /usr/local/lib/python3.5/dist-packages\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /usr/lib/python3/dist-packages (from nltk)\n",
      "Requirement already satisfied (use --upgrade to upgrade): singledispatch in /usr/local/lib/python3.5/dist-packages (from nltk)\n",
      "\u001b[33mYou are using pip version 8.1.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english')).union({\n",
    "    'introduction', 'edition', 'series', 'application',\n",
    "    'approach', 'card', 'access', 'package', 'plus', 'etext',\n",
    "    'brief', 'vol', 'fundamental', 'guide', 'essential', 'printed',\n",
    "    'third', 'second', 'fourth'})\n",
    "\n",
    "sc = SparkContext('local', 'nlp')\n",
    "lines = sc.textFile('all_book_titles.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = lines \\\n",
    "    .map(lambda line: line.strip().lower()) \\\n",
    "    .map(lambda line: line.split()) \\\n",
    "    .map(lambda words: [w for w in words if w.isalpha()]) \\\n",
    "    .map(lambda words: [w for w in words if len(w) > 3]) \\\n",
    "    .map(lambda words: [w for w in words if w not in stopwords]).reduce(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sess.createDataFrame([(lines,), (lines,)], [\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            sentence|\n",
      "+--------------------+\n",
      "|[philosophy, love...|\n",
      "|[philosophy, love...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=64, inputCol=\"sentence\", outputCol=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2Vec.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------+\n",
      "|        word|              vector|\n",
      "+------------+--------------------+\n",
      "|    embedded|[0.02133640460669...|\n",
      "|    feminism|[0.03890470042824...|\n",
      "|       unity|[-0.0120630841702...|\n",
      "|  conceptual|[-0.0345687717199...|\n",
      "|   reference|[-0.0031733114738...|\n",
      "|    workbook|[0.01257053948938...|\n",
      "|     writing|[-0.0387185476720...|\n",
      "|    elements|[-0.0082433093339...|\n",
      "|    discrete|[0.01831728033721...|\n",
      "|    semester|[-0.0221984051167...|\n",
      "|     measure|[0.02612338773906...|\n",
      "|      health|[0.09340767562389...|\n",
      "|     statics|[-0.0189717188477...|\n",
      "|  perceptive|[-0.0406614504754...|\n",
      "|organization|[0.19586075842380...|\n",
      "|    database|[0.05999059230089...|\n",
      "|       moral|[9.99550218693912...|\n",
      "|     nursing|[0.11989702284336...|\n",
      "|    politics|[-0.0118664680048...|\n",
      "|    eleventh|[-0.0475022606551...|\n",
      "+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.getVectors().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number as fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     word|similarity|\n",
      "+---------+----------+\n",
      "| american|   0.75948|\n",
      "|   survey|   0.73565|\n",
      "|    latin|   0.70667|\n",
      "|  society|   0.69553|\n",
      "|democracy|   0.69158|\n",
      "| diaspora|   0.68637|\n",
      "| ultimate|   0.68329|\n",
      "|  america|   0.68231|\n",
      "|paperback|   0.68097|\n",
      "|     west|   0.68061|\n",
      "|  history|   0.67355|\n",
      "|political|   0.66569|\n",
      "| critical|   0.66167|\n",
      "|sociology|   0.64909|\n",
      "|  matters|   0.63970|\n",
      "|   source|   0.62940|\n",
      "|documents|   0.62534|\n",
      "|  concise|   0.61480|\n",
      "|    blood|   0.61417|\n",
      "|     exam|   0.61149|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.findSynonyms(\"politics\", 20).select(\"word\", fmt(\"similarity\", 5).alias(\"similarity\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
